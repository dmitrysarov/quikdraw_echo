{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers as layers_lib\n",
    "from tensorflow.contrib.slim.nets import resnet_v2, resnet_utils\n",
    "from tensorflow.contrib.slim import batch_norm\n",
    "resnet_v2_block = resnet_v2.resnet_v2_block\n",
    "resnet_v2 = resnet_v2.resnet_v2\n",
    "\n",
    "from tensorflow.contrib import slim\n",
    "# session_config=tf.ConfigProto(\n",
    "#         gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.05, allow_growth=True), allow_soft_placement=True, log_device_placement=False)\n",
    "# sess = tf.Session(config=session_config)\n",
    "config = tf.ConfigProto(allow_soft_placement = True)\n",
    "sess = tf.Session(config = config)\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source:\n",
    "# https://stackoverflow.com/questions/38559755/how-to-get-current-available-gpus-in-tensorflow\n",
    "def get_available_gpus():\n",
    "    \"\"\"\n",
    "        Returns a list of the identifiers of all visible GPUs.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.client import device_lib\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "CPUS = multiprocessing.cpu_count()\n",
    "BASE_SIZE = 256\n",
    "BATCH_SIZE = 256\n",
    "VAL_BATCH_SIZE = 1024\n",
    "VAL_STEPS = 2**16\n",
    "GPUS = get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_v2_26_base(inputs,\n",
    "                 num_classes=None,\n",
    "                 is_training=True, # True - due to update batchnorm layers\n",
    "                 global_pool=True,\n",
    "                 output_stride=16, # effective stride \n",
    "                 reuse=None,\n",
    "                 include_root_block=False, #first conv layer. Removed due to max pool supression. We need large receprive field\n",
    "                 scope='resnet_v2_26'):\n",
    "  \n",
    "    \"\"\"\n",
    "    Tensorflow resnet_v2 use only bottleneck blocks (consist of 3 layers).\n",
    "    Thus, this resnet layer model consist of 26 layers.\n",
    "    I put stride = 2 on each block due to increase receptive field.\n",
    "\n",
    "    \"\"\"\n",
    "    blocks = [\n",
    "      resnet_v2_block('block1', base_depth=64, num_units=3, stride=2),\n",
    "      resnet_v2_block('block2', base_depth=128, num_units=4, stride=2),\n",
    "      resnet_v2_block('block3', base_depth=256, num_units=6, stride=2),\n",
    "      resnet_v2_block('block4', base_depth=512, num_units=3, stride=1),\n",
    "    ]\n",
    "    return resnet_v2(\n",
    "      inputs,\n",
    "      blocks,\n",
    "      num_classes,\n",
    "      is_training,\n",
    "      global_pool,\n",
    "      output_stride,\n",
    "      include_root_block,\n",
    "      reuse=reuse,\n",
    "      scope=scope)\n",
    "\n",
    "def make_resnet(inputs, num_classes, is_training=True):\n",
    "    '''\n",
    "    Creates neural network graph.\n",
    "    Image width halved and it's define timestamps width (feature sequence length) \n",
    "    No activation after output (no softmax), due to it's presence at ctc_loss() and beam_search().\n",
    "    After resnet head features are resized to be [batch,1,width,channel], and after that goes 1x1 conv \n",
    "    to make anology of dense connaction for each timestamp.\n",
    "    \n",
    "    input: batch of images\n",
    "    output: tensor of size [batch, time_stamps_width, num_classes]\n",
    "    '''\n",
    "    input_image_batch, countrycode, image_ratio, min_veloc, max_veloc = inputs\n",
    "    with tf.variable_scope('resnet_base', values=[input_image_batch]) as sc:\n",
    "        with slim.arg_scope([slim.conv2d], activation_fn=None, normalizer_fn=None):\n",
    "            net = resnet_utils.conv2d_same(input_image_batch, 64, 7, stride=2, scope='conv1') #root conv for resnet\n",
    "            net = slim.max_pool2d(net, [3, 3], stride=2, scope='pool1') # due to enlarge of receptive field\n",
    "            net = resnet_v2_26_base(net, output_stride=8, is_training = is_training)[0] # ouput is a tuple of last tensor and all tensors \n",
    "    with tf.variable_scope('class_head', values=[net]) as sc:\n",
    "\n",
    "        net = tf.reduce_max(net, axis=[1,2])\n",
    "        net = tf.concat((net, countrycode, image_ratio, min_veloc, max_veloc), axis=1, name='concat_aulux')\n",
    "#         print_tensor = tf.print(image_ratio, 'my output')\n",
    "#         with tf.control_dependencies([print_tensor]):\n",
    "        net = tf.layers.dense(net, 256, activation=tf.nn.relu)\n",
    "        net = batch_norm(net, is_training=is_training, activation_fn=None)\n",
    "        net = tf.layers.dense(net, num_classes, activation=tf.nn.sigmoid)\n",
    "        return net #tf.squeeze(net,axis=[1,2])\n",
    "\n",
    "def get_training(net_logits, target_values, \n",
    "                   learning_rate=1e-4, decay_steps=2**16, decay_rate=0.9, decay_staircase=False, \n",
    "                   momentum=0.9):\n",
    "    \"\"\"\n",
    "    Set up training ops\n",
    "    https://github.com/weinman/cnn_lstm_ctc_ocr/blob/master/src/model_fn.py\n",
    "    \"\"\"\n",
    "    with tf.name_scope( \"train\" ):\n",
    "        net_logits_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "        losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=target_values, logits=net_logits) \n",
    "        loss_mean = tf.reduce_mean(losses, name='cross_entropy')\n",
    "        # Update batch norm stats [http://stackoverflow.com/questions/43234667]\n",
    "        extra_update_ops = tf.get_collection( tf.GraphKeys.UPDATE_OPS )\n",
    "        with tf.control_dependencies( extra_update_ops ):\n",
    "            # Calculate the learning rate given the parameters\n",
    "#             learning_rate_tensor = tf.train.exponential_decay(\n",
    "#                 learning_rate,\n",
    "#                 tf.train.get_global_step(),\n",
    "#                 decay_steps,\n",
    "#                 decay_rate,\n",
    "#                 staircase=decay_staircase,\n",
    "#                 name='learning_rate' )\n",
    "            learning_rate_tensor = learning_rate\n",
    "            optimizer = tf.train.AdamOptimizer(\n",
    "                learning_rate=learning_rate_tensor,\n",
    "                beta1=momentum )\n",
    "            train_op = tf.contrib.layers.optimize_loss(\n",
    "                loss=loss_mean,\n",
    "                global_step=tf.train.get_global_step(),\n",
    "                learning_rate=learning_rate_tensor, \n",
    "                optimizer=optimizer,\n",
    "                variables=net_logits_vars)\n",
    "    return train_op, loss_mean, learning_rate_tensor\n",
    "\n",
    "PS_OPS = [\n",
    "    'Variable', 'VariableV2', 'AutoReloadVariable', 'MutableHashTable',\n",
    "    'MutableHashTableOfTensors', 'MutableDenseHashTable'\n",
    "]\n",
    "    \n",
    "# see https://github.com/tensorflow/tensorflow/issues/9517\n",
    "def assign_to_device(device, ps_device):\n",
    "    \"\"\"Returns a function to place variables on the ps_device.\n",
    "\n",
    "    Args:\n",
    "        device: Device for everything but variables\n",
    "        ps_device: Device to put the variables on. Example values are /GPU:0 and /CPU:0.\n",
    "\n",
    "    If ps_device is not set then the variables will be placed on the default device.\n",
    "    The best device for shared varibles depends on the platform as well as the\n",
    "    model. Start with CPU:0 and then test GPU:0 to see if there is an\n",
    "    improvement.\n",
    "    \"\"\"\n",
    "    def _assign(op):\n",
    "        node_def = op if isinstance(op, tf.NodeDef) else op.node_def\n",
    "        if node_def.op in PS_OPS:\n",
    "            return ps_device\n",
    "        else:\n",
    "            return device\n",
    "    return _assign  \n",
    "\n",
    "# Source:\n",
    "# https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py#L101\n",
    "def average_gradients(tower_grads):\n",
    "    \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "    Note that this function provides a synchronization point across all towers.\n",
    "    Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list ranges\n",
    "        over the devices. The inner list ranges over the different variables.\n",
    "    Returns:\n",
    "            List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "            across all towers.\n",
    "    \"\"\"\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = [g for g, _ in grad_and_vars]\n",
    "        grad = tf.reduce_mean(grads, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(object):\n",
    "    \n",
    "    def __init__(self, num_classes, is_training, input_shape = [None, None, None, 6], learning_rate=1e-4,\n",
    "                decay_steps=2**16, decay_rate=0.9, decay_staircase=False, momentum=0.9):\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.is_training = tf.cast(is_training, tf.bool)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.decay_rate = decay_rate \n",
    "        self.decay_staircase = decay_staircase\n",
    "        self.momentum = momentum\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def build_for_train(self, input_image_batch, target_values):\n",
    "        input_image_batch.set_shape(self.input_shape)\n",
    "        net = make_resnet(input_image_batch, self.num_classes, is_training=self.is_training)\n",
    "        self.train_op, self.loss, self.learning_rate_tensor = get_training(net, target_values,\n",
    "                                                self.learning_rate, self.decay_steps, \n",
    "                                                self.decay_rate, self.decay_staircase, self.momentum)\n",
    "        top_3_metric = tf.cast(tf.nn.in_top_k(targets=target_values, predictions=net, k=3),tf.float32)\n",
    "        self.top_3_metric = tf.reduce_mean(top_3_metric)\n",
    "        with tf.name_scope('prediction_metrics'):\n",
    "            tf.summary.scalar('sparse_softmax_cross_entropy_with_logits', self.loss)\n",
    "            tf.summary.scalar('Top_3_metric', self.top_3_metric)\n",
    "            tf.summary.scalar('Learning_rate', self.learning_rate_tensor)\n",
    "        self.merged_summary_metrics = tf.summary.merge_all(scope='prediction_metrics')\n",
    "\n",
    "        \n",
    "    def build_for_prediction(self, input_image_batch):\n",
    "        \n",
    "        self.input_image_batch = input_image_batch\n",
    "        net = make_ocr_net(self.input_image_batch, self.num_classes, is_training=self.is_training)\n",
    "        self.net = net\n",
    "        self.prediction = get_prediction(net, [tf.shape(self.net)[1]], merge_repeated=False) # tuple(decoded, prob). decoded - list of top paths. I use top1\n",
    "        pred_dense = tf.sparse_to_dense(self.prediction[0][0].indices, self.prediction[0][0].dense_shape, \n",
    "                                               self.prediction[0][0].values)\n",
    "        self.pred_dense = pred_dense\n",
    "        self.prediction_string = tf.reduce_join(self.table.lookup(tf.cast(pred_dense, tf.int64)-1))\n",
    "        \n",
    "    def build_in_parallel_fashion(self, input_fn, devices, controller):\n",
    "        '''\n",
    "        http://blog.s-schoener.com/2017-12-15-parallel-tensorflow-intro/\n",
    "        '''        \n",
    "        # This list keeps track of the gradients per tower and the losses\n",
    "        tower_grads = []\n",
    "        losses = []\n",
    "        top_3_metrics = []\n",
    "\n",
    "        # Get the current variable scope so we can reuse all variables we need once we get\n",
    "        # to the second iteration of the loop below\n",
    "#         self.learning_rate_tensor = tf.train.exponential_decay(\n",
    "#             self.learning_rate,\n",
    "#             tf.train.get_global_step(),\n",
    "#             self.decay_steps,\n",
    "#             self.decay_rate,\n",
    "#             staircase=self.decay_staircase,\n",
    "#             name='learning_rate' )\n",
    "        self.learning_rate_tensor = self.learning_rate\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate_tensor,\n",
    "                                            beta1=self.momentum )\n",
    "        with tf.variable_scope(tf.get_variable_scope()) as outer_scope:\n",
    "            for i, id in enumerate(devices):\n",
    "                name = 'tower_{}'.format(i)\n",
    "                # Use the assign_to_device function to ensure that variables are created on the\n",
    "                # controller.\n",
    "                with tf.device(assign_to_device(id, controller)), tf.name_scope(name):\n",
    "\n",
    "                    # Compute loss and gradients, but don't apply them yet\n",
    "                    input_image_batch, target_values, countrycode, image_ratio, min_veloc, max_veloc = input_fn()\n",
    "                    input_image_batch.set_shape(self.input_shape)\n",
    "                    countrycode.set_shape([None, len(cat_to_id['country_codes'])])\n",
    "                    image_ratio.set_shape([None, 1])\n",
    "                    min_veloc.set_shape([None, 1])\n",
    "                    max_veloc.set_shape([None, 1])\n",
    "#                     print_tensor = tf.print(image_ratio, 'net got {}'.format(i))\n",
    "#                     with tf.control_dependencies([print_tensor]):                    \n",
    "                    net_logits = make_resnet((input_image_batch, countrycode, image_ratio, min_veloc, max_veloc), self.num_classes, is_training=self.is_training)\n",
    "#                     with tf.name_scope( \"train\" ):\n",
    "                    net_logits_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "                    loss_gpu_wise = tf.reduce_mean(\n",
    "                        tf.nn.sparse_softmax_cross_entropy_with_logits(labels=target_values, logits=net_logits), \n",
    "                        name='cross_entropy')\n",
    "                    # Update batch norm stats [http://stackoverflow.com/questions/43234667]\n",
    "                    extra_update_ops = tf.get_collection( tf.GraphKeys.UPDATE_OPS )\n",
    "                        \n",
    "                    with tf.name_scope(\"compute_gradients\"):\n",
    "                        with tf.control_dependencies( extra_update_ops ):\n",
    "                            # `compute_gradients` returns a list of (gradient, variable) pairs\n",
    "                            grads = optimizer.compute_gradients(loss_gpu_wise)\n",
    "                            tower_grads.append(grads)\n",
    "\n",
    "                    losses.append(loss_gpu_wise)\n",
    "                    top_3_metric_gpu_wise = tf.reduce_mean(tf.cast(tf.nn.in_top_k(targets=target_values, predictions=net_logits, k=3),tf.float32))\n",
    "                    top_3_metrics.append(top_3_metric_gpu_wise)\n",
    "                # After the first iteration, we want to reuse the variables.\n",
    "                outer_scope.reuse_variables()\n",
    "\n",
    "        # Apply the gradients on the controlling device\n",
    "        with tf.name_scope(\"apply_gradients\"), tf.device(controller):\n",
    "            # Note that what we are doing here mathematically is equivalent to returning the\n",
    "            # average loss over the towers and compute the gradients relative to that.\n",
    "            # Unfortunately, this would place all gradient-computations on one device, which is\n",
    "            # why we had to compute the gradients above per tower and need to average them here.\n",
    "\n",
    "            # This function is defined below; it takes the list of (gradient, variable) lists\n",
    "            # and turns it into a single (gradient, variables) list.\n",
    "            gradients = average_gradients(tower_grads)\n",
    "            global_step = tf.train.get_global_step()\n",
    "            self.train_op = optimizer.apply_gradients(gradients, global_step)\n",
    "            self.loss = tf.reduce_mean(losses)\n",
    "            self.top_3_metric = tf.reduce_mean(top_3_metrics)\n",
    "            \n",
    "            \n",
    "            tf.summary.scalar('sparse_softmax_cross_entropy_with_logits', self.loss)\n",
    "            tf.summary.scalar('Top_3_metric', self.top_3_metric)\n",
    "            tf.summary.scalar('Learning_rate', self.learning_rate_tensor)\n",
    "            self.merged_summary_metrics = tf.summary.merge_all(scope='apply_gradients')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x = x.astype(np.float32)\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_mat_to_img(mat):\n",
    "    mat-=mat.min()\n",
    "    mat/=mat.max()\n",
    "    mat*=255\n",
    "    return mat.astype(np.uint8)\n",
    "\n",
    "def common_draw_cv2(raw_strokes, veloc, size=256, lw=6, time_color=True):\n",
    "    img_veloc = np.zeros((BASE_SIZE, BASE_SIZE), np.float32)\n",
    "    img_strok_order = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "\n",
    "    for t, (s, v) in enumerate(zip(raw_strokes, veloc)):\n",
    "        img_blank = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "        color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "        for i in range(len(s[0]) - 1):\n",
    "            _ = cv2.line(img_blank, (s[0][i], s[1][i]),\n",
    "                         (s[0][i + 1], s[1][i + 1]), color, lw)\n",
    "        img_strok_order = np.maximum(img_strok_order, img_blank)\n",
    "        img_veloc += (img_blank.astype(np.bool).astype(np.uint8))*(1/v) #slower more importaint\n",
    "            \n",
    "    img_veloc = cv2.applyColorMap(norm_mat_to_img(img_veloc), cv2.COLORMAP_JET)\n",
    "    img_strok_order = cv2.applyColorMap(img_strok_order, cv2.COLORMAP_JET)\n",
    "\n",
    "    image = preprocess_input(np.concatenate((img_veloc, img_strok_order), axis=-1))\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(image, (size, size, 6))\n",
    "    else:\n",
    "        return image   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_func(countrycode, drawing, label, veloc, image_ratio):\n",
    "    drawing = drawing.decode('utf-8')\n",
    "    drawing = json.loads(drawing)\n",
    "    veloc = veloc.decode('utf-8').replace('nan','-1').replace('inf','-1').replace('[array(','').replace(')]','').replace('.,',',').replace('.]',']')\n",
    "    veloc = json.loads(veloc)\n",
    "    veloc = np.array(veloc) #hack for zero and nans in veloc values\n",
    "\n",
    "    if len(veloc) == 1:\n",
    "        veloc = [1]\n",
    "    elif np.all(veloc == veloc[0]):\n",
    "        veloc = np.ones(len(veloc))\n",
    "    elif set(veloc) == set([0,-1]):\n",
    "        veloc[veloc==-1] = 1\n",
    "        veloc[veloc==0] = 0.1\n",
    "    else:\n",
    "        veloc[veloc==-1] = np.max(veloc[veloc!=-1])\n",
    "        veloc[veloc==0] = np.min(veloc[veloc!=0])        \n",
    "    min_veloc = np.expand_dims(np.min(veloc), 0)\n",
    "    max_veloc = np.expand_dims(np.max(veloc), 0)\n",
    "\n",
    "    veloc = list(veloc)\n",
    "    \n",
    "    label = label.decode('utf-8')\n",
    "    label = cat_to_id['labels'][label]\n",
    "    countrycode = countrycode.decode('utf-8')\n",
    "    countrycode = cat_to_id['country_codes'][countrycode]   \n",
    "    countrycode = tf.keras.utils.to_categorical(countrycode, num_classes=len(cat_to_id['country_codes']))\n",
    "    \n",
    "    image_ratio = np.expand_dims(image_ratio, 0)\n",
    "\n",
    "    image = common_draw_cv2(drawing, veloc, size=256, lw=6, time_color=True)\n",
    "    return (image.astype(np.float32), \n",
    "            np.int32(label), \n",
    "            countrycode.astype(np.float32), \n",
    "            np.float32(image_ratio), \n",
    "            np.float32(min_veloc),\n",
    "            np.float32(max_veloc))\n",
    "\n",
    "def tf_py_map_func_wrapper(*args):\n",
    "    return tf.py_func(func=map_func,\n",
    "               inp=(args[0], args[1], args[2], args[3], args[4]),\n",
    "               Tout = (tf.float32, tf.int32, tf.float32, tf.float32, tf.float32, tf.float32),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config_label_country_code.json','r') as f:\n",
    "    cat_to_id = json.load(f)\n",
    "id_to_cat_label = {v:k.replace(' ','_') for k,v in cat_to_id['labels'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    validation_dataset = tf.data.experimental.CsvDataset(glob.glob('val_simplified_extend_clearn_split.csv'), [tf.string, tf.string, tf.string, tf.string, tf.float32], header=True, select_cols=[2, 3, 7, 8, 9],).map(tf_py_map_func_wrapper, num_parallel_calls=CPUS).prefetch(len(GPUS)*VAL_BATCH_SIZE).batch(VAL_BATCH_SIZE).repeat(-1)\n",
    "    training_dataset = tf.data.experimental.CsvDataset(glob.glob('train_simplified_extend_clearn_split.csv'), [tf.string, tf.string, tf.string, tf.string, tf.float32], header=True, select_cols=[2, 3, 7, 8, 9]).skip((19506+4822)*1024).shuffle(int(1e4)).map(tf_py_map_func_wrapper, num_parallel_calls=CPUS).prefetch(len(GPUS)*BATCH_SIZE).batch(BATCH_SIZE).repeat(-1)\n",
    "    \n",
    "    handle = tf.placeholder(tf.string, shape=[], name='iterator_handler')\n",
    "    iterator = tf.data.Iterator.from_string_handle(handle, training_dataset.output_types, training_dataset.output_shapes)\n",
    "    def input_fn():\n",
    "        with tf.device(None):\n",
    "            # remove any device specifications for the input data\n",
    "            data = iterator.get_next()\n",
    "            return data\n",
    "    training_iterator = training_dataset.make_initializable_iterator()    \n",
    "    validation_iterator = validation_dataset.make_initializable_iterator()\n",
    "    \n",
    "    tf.train.create_global_step()\n",
    "    \n",
    "    is_training = tf.placeholder_with_default(1, shape=[], name='isTraining')\n",
    "    model = MyModel(num_classes=len(cat_to_id['labels']), is_training=is_training, learning_rate=1e-3)\n",
    "    model.build_in_parallel_fashion(input_fn, controller='/cpu:0', devices=GPUS)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from models/resnet_checkpoints/model_0.897216796875.ckpt\n",
      "1018\r"
     ]
    }
   ],
   "source": [
    "STEMPS_NUM = int(5e7/(BATCH_SIZE*len(GPUS)))*10\n",
    "LOG_DIR = 'models/resnet_checkpoints'\n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "# config.log_device_placement=True\n",
    "with tf.Session(graph=graph, config=config) as sess:\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(LOG_DIR,'train'), sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(os.path.join(LOG_DIR, 'test'))\n",
    "    \n",
    "    sess.run([init, training_iterator.initializer, validation_iterator.initializer])\n",
    "    training_handle = sess.run(training_iterator.string_handle())\n",
    "    validation_handle = sess.run(validation_iterator.string_handle())\n",
    "    \n",
    "    top_3_metric = 0\n",
    "    validation_top_3_metric_list = []\n",
    "    validation_loss_list = []\n",
    "    \n",
    "    saver.restore(sess, os.path.join(LOG_DIR,\"model_0.897216796875.ckpt\"))\n",
    "    for train_step in range(STEMPS_NUM):\n",
    "        \n",
    "        print(train_step, end='\\r')\n",
    "        _, ms = sess.run([model.train_op, model.merged_summary_metrics], {handle: training_handle,\n",
    "                                                                         is_training: 1})\n",
    "        if train_step%10==0:\n",
    "            train_writer.add_summary(ms, train_step)\n",
    "            train_writer.flush()\n",
    "        \n",
    "        if train_step%1000==0:\n",
    "            for val_step in range(int(VAL_STEPS/(VAL_BATCH_SIZE*len(GPUS)))):\n",
    "                validation_loss, validation_top_3_metric_step = sess.run([model.loss, model.top_3_metric], {handle: validation_handle,\n",
    "                                                                                                           is_training: 0})\n",
    "                validation_top_3_metric_list.append(validation_top_3_metric_step)\n",
    "                validation_loss_list.append(validation_loss)\n",
    "            summary = tf.Summary()\n",
    "            summary.value.add(tag=\"Validation_loss\", simple_value=np.mean(validation_loss_list))\n",
    "            summary.value.add(tag=\"Validation_Top3_metric\", simple_value=np.mean(validation_top_3_metric_list))\n",
    "            test_writer.add_summary(summary, train_step)\n",
    "            test_writer.flush()\n",
    "            if np.mean(validation_top_3_metric_step) > top_3_metric:\n",
    "                top_3_metric = np.mean(validation_top_3_metric_step)\n",
    "                saver.save(sess, os.path.join(LOG_DIR, \"model_{}.ckpt\".format(top_3_metric)))\n",
    "            top_3_metric_list = []\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
