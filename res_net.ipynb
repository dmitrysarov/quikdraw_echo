{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.metrics import categorical_crossentropy, categorical_accuracy, top_k_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "CPUS = multiprocessing.cpu_count()\n",
    "BASE_SIZE = 200\n",
    "BATCH_SIZE = 128\n",
    "size = 256\n",
    "PRED_BATCHSIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPUS = 1\n",
    "NCATS = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x = x.astype(np.float32)\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as f:\n",
    "    cat_to_id = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and data feed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-dc37b912deec>:33: CsvDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.CsvDataset(...)`.\n"
     ]
    }
   ],
   "source": [
    "def top_3_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
    "def draw_cv2(raw_strokes, size=256, lw=6, time_color=True):\n",
    "    img = np.zeros((BASE_SIZE, BASE_SIZE), np.uint8)\n",
    "    for t, stroke in enumerate(raw_strokes):\n",
    "        for i in range(len(stroke[0]) - 1):\n",
    "            color = 255 - min(t, 10) * 13 if time_color else 255\n",
    "            _ = cv2.line(img, (stroke[0][i], stroke[1][i]),\n",
    "                         (stroke[0][i + 1], stroke[1][i + 1]), color, lw)\n",
    "    if size != BASE_SIZE:\n",
    "        return cv2.resize(img, (size, size))\n",
    "    else:\n",
    "        return img\n",
    "def map_func(drawing, label):\n",
    "    drawing = drawing.decode('utf-8')\n",
    "#     label = label.decode('utf-8')\n",
    "#     label = cat_to_id[label]\n",
    "    label = keras.utils.to_categorical(label, num_classes=NCATS)\n",
    "    drawing = json.loads(drawing)\n",
    "    image = draw_cv2(drawing, size=256, lw=6, time_color=True)\n",
    "    image = preprocess_input(image)\n",
    "    return np.expand_dims(image,-1).astype(np.float32), label.astype(np.float32)\n",
    "\n",
    "def tf_py_map_func_wrapper(*args):\n",
    "    return tf.py_func(func=map_func,\n",
    "               inp=(args[0], args[1]),\n",
    "               Tout = (tf.float32, tf.float32))\n",
    "def set_shape_func(img, label):\n",
    "    img.set_shape([None, None, 1])\n",
    "    label.set_shape([NCATS])\n",
    "    return img, label\n",
    "\n",
    "dataset = tf.contrib.data.CsvDataset(glob.glob('train_simplified.csv'), [tf.string, tf.float32], header=True, select_cols=[2, 7])\n",
    "\n",
    "val_dataset = dataset.take(2**14).map(tf_py_map_func_wrapper, num_parallel_calls=CPUS).map(set_shape_func).prefetch(GPUS*PRED_BATCHSIZE).batch(PRED_BATCHSIZE).repeat(-1)\n",
    "train_dataset = dataset.skip(2**14).shuffle(int(1e4)).map(tf_py_map_func_wrapper, num_parallel_calls=CPUS).map(set_shape_func).prefetch(GPUS*BATCH_SIZE).batch(BATCH_SIZE).repeat(-1)\n",
    "# iterator = dataset.make_one_shot_iterator()\n",
    "# feature, label = iterator.get_next()\n",
    "train_iterator = train_dataset.make_one_shot_iterator()\n",
    "val_iterator = val_dataset.make_one_shot_iterator()\n",
    "model = keras.applications.resnet50.ResNet50(input_shape=(size, size, 1), weights=None, classes=NCATS)\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "# multigpu_model = keras.utils.multi_gpu_model(model,gpus=GPUS,)\n",
    "# multigpu_model.compile(optimizer=keras.optimizers.Adam(), loss='categorical_crossentropy', \n",
    "#                        metrics = [categorical_crossentropy, categorical_accuracy, top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "22723/38821 [================>.............] - ETA: 2:35:06 - loss: 1.6386 - categorical_crossentropy: 1.6386 - categorical_accuracy: 0.6096 - top_3_accuracy: 0.7882"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35800/38821 [==========================>...] - ETA: 29:06 - loss: 1.4508 - categorical_crossentropy: 1.4508 - categorical_accuracy: 0.6479 - top_3_accuracy: 0.8202"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38821/38821 [==============================] - 22501s 580ms/step - loss: 1.4219 - categorical_crossentropy: 1.4219 - categorical_accuracy: 0.6540 - top_3_accuracy: 0.8250 - val_loss: 1.0519 - val_categorical_crossentropy: 1.0519 - val_categorical_accuracy: 0.7292 - val_top_3_accuracy: 0.8864\n",
      "Epoch 2/2\n",
      " 2728/38821 [=>............................] - ETA: 5:48:07 - loss: 1.0672 - categorical_crossentropy: 1.0672 - categorical_accuracy: 0.7275 - top_3_accuracy: 0.8838"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8310/38821 [=====>........................] - ETA: 4:54:06 - loss: 1.0543 - categorical_crossentropy: 1.0543 - categorical_accuracy: 0.7300 - top_3_accuracy: 0.8859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13815/38821 [=========>....................] - ETA: 4:01:01 - loss: 1.0437 - categorical_crossentropy: 1.0437 - categorical_accuracy: 0.7328 - top_3_accuracy: 0.8874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19168/38821 [=============>................] - ETA: 3:09:26 - loss: 1.0347 - categorical_crossentropy: 1.0347 - categorical_accuracy: 0.7348 - top_3_accuracy: 0.8887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24327/38821 [=================>............] - ETA: 2:19:40 - loss: 1.0269 - categorical_crossentropy: 1.0269 - categorical_accuracy: 0.7366 - top_3_accuracy: 0.8898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30093/38821 [======================>.......] - ETA: 1:24:06 - loss: 1.0188 - categorical_crossentropy: 1.0188 - categorical_accuracy: 0.7386 - top_3_accuracy: 0.8909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35731/38821 [==========================>...] - ETA: 29:46 - loss: 1.0120 - categorical_crossentropy: 1.0120 - categorical_accuracy: 0.7403 - top_3_accuracy: 0.8919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38821/38821 [==============================] - 22472s 579ms/step - loss: 1.0083 - categorical_crossentropy: 1.0083 - categorical_accuracy: 0.7412 - top_3_accuracy: 0.8925 - val_loss: 0.9517 - val_categorical_crossentropy: 0.9517 - val_categorical_accuracy: 0.7524 - val_top_3_accuracy: 0.9014\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'models/resnet'\n",
    "callbacks = [\n",
    "#     ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.75, patience=3, min_delta=0.001,\n",
    "#                           mode='max', min_lr=1e-5, verbose=1),\n",
    "    ModelCheckpoint(log_dir + '/res_net_{val_top_3_accuracy:.2f}.h5', monitor='val_top_3_accuracy', mode='max', save_best_only=True,\n",
    "                    save_weights_only=True),\n",
    "    TensorBoard(log_dir = log_dir)\n",
    "]\n",
    "hists = []\n",
    "hist = model.fit(train_iterator, \n",
    "                          steps_per_epoch=int((49707579-2**14)/(10*BATCH_SIZE)), \n",
    "                          epochs=2,\n",
    "                          validation_data=val_iterator,\n",
    "                          validation_steps=int(2**14/PRED_BATCHSIZE),\n",
    "                          callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/resnet/res_net_0.90.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/128 [==============================] - 93s 726ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9516998622566462, 0.9516998622566462, 0.75244140625, 0.9013671875]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset.make_one_shot_iterator(), steps=int(2**14/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_map_func(drawing):\n",
    "    drawing = drawing.decode('utf-8')\n",
    "    drawing = json.loads(drawing)\n",
    "    image = draw_cv2(drawing, size=256, lw=6, time_color=True)\n",
    "    image = preprocess_input(image)\n",
    "    return np.expand_dims(image,-1).astype(np.float32), np.float32(1) # hack of 2 values bug\n",
    "def pred_tf_py_map_func_wrapper(*args):\n",
    "    return tf.py_func(func=pred_map_func,\n",
    "               inp=(args),\n",
    "               Tout = (tf.float32, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = tf.contrib.data.CsvDataset(glob.glob('test_simplified.csv'), [tf.string], header=True, select_cols=[2])\n",
    "pred_dataset = pred_dataset.map(pred_tf_py_map_func_wrapper, num_parallel_calls=CPUS).map(set_shape_func).prefetch(CPUS*PRED_BATCHSIZE).batch(PRED_BATCHSIZE)\n",
    "predict = model.predict(pred_dataset.make_one_shot_iterator(), steps = int((112199+PRED_BATCHSIZE)/PRED_BATCHSIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('res_predict_for_blend_test.pkl','wb') as f:\n",
    "    pickle.dump(predict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_cat = {v:k.replace(' ', '_') for k,v in cat_to_id.items()}\n",
    "def get_top_cat(prediction, id_to_cat, k=3):\n",
    "    top_k_ids = np.argsort(predict, axis=1)[:,::-1][:,:3]\n",
    "    top_cat = np.vectorize(id_to_cat.get)(top_k_ids)\n",
    "    return top_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['radio stereo train',\n",
       " 'hockey_puck bottlecap pool',\n",
       " 'The_Great_Wall_of_China castle crown',\n",
       " 'mountain triangle tent',\n",
       " 'campfire fireplace fire_hydrant',\n",
       " 'fence spreadsheet stitches',\n",
       " 'wine_glass shovel spoon',\n",
       " 'submarine lobster baseball_bat',\n",
       " 'bracelet wristwatch hand',\n",
       " 'hourglass vase wine_glass']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3_cat = get_top_cat(predict, id_to_cat)\n",
    "top3_concat = [' '.join(i) for i in top3_cat]\n",
    "top3_concat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>drawing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000003627287624</td>\n",
       "      <td>DE</td>\n",
       "      <td>[[[17, 18, 20, 25, 137, 174, 242, 249, 251, 25...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000010688666847</td>\n",
       "      <td>UA</td>\n",
       "      <td>[[[174, 145, 106, 38, 11, 4, 4, 15, 29, 78, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000023642890129</td>\n",
       "      <td>BG</td>\n",
       "      <td>[[[0, 12, 14, 17, 16, 24, 55, 57, 60, 79, 82, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000038588854897</td>\n",
       "      <td>US</td>\n",
       "      <td>[[[0, 9, 23, 40, 54, 60, 81, 105, 123, 167, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000052667981386</td>\n",
       "      <td>AR</td>\n",
       "      <td>[[[87, 82, 71, 63, 66, 92, 96, 95], [220, 218,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id countrycode  \\\n",
       "0  9000003627287624          DE   \n",
       "1  9000010688666847          UA   \n",
       "2  9000023642890129          BG   \n",
       "3  9000038588854897          US   \n",
       "4  9000052667981386          AR   \n",
       "\n",
       "                                             drawing  \n",
       "0  [[[17, 18, 20, 25, 137, 174, 242, 249, 251, 25...  \n",
       "1  [[[174, 145, 106, 38, 11, 4, 4, 15, 29, 78, 16...  \n",
       "2  [[[0, 12, 14, 17, 16, 24, 55, 57, 60, 79, 82, ...  \n",
       "3  [[[0, 9, 23, 40, 54, 60, 81, 105, 123, 167, 20...  \n",
       "4  [[[87, 82, 71, 63, 66, 92, 96, 95], [220, 218,...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test_simplified.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word'] = top3_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['drawing','countrycode'], axis=1).to_csv('res_submission_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction for blend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dataset = tf.contrib.data.CsvDataset(glob.glob('train_simplified.csv'), [tf.string], header=True, select_cols=[2])\n",
    "pred_dataset = pred_dataset.take(2**17).map(pred_tf_py_map_func_wrapper, num_parallel_calls=CPUS).map(set_shape_func).prefetch(CPUS*PRED_BATCHSIZE).batch(PRED_BATCHSIZE)\n",
    "predict = model.predict(pred_dataset.make_one_shot_iterator(), steps = int((2**17)/PRED_BATCHSIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('res_predict_for_blend_train.pkl','wb') as f:\n",
    "    pickle.dump(predict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
